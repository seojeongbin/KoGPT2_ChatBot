{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as tr \n",
    "from torch.utils.data import DataLoader, Dataset "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### pytorch 내장 데이터 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "transf = tr.Compose([tr.ToTensor(),\n",
    "                     tr.Normalize((0.5, 0.5, 0.5),(0.5,0.5,0.5))]) # torch 내장 데이터(pil이미지를 받는것이므로)니까 그냥 내장 ToTensor 이용해도 됨\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transf)\n",
    "trainloader = DataLoader(trainset, batch_size=8, shuffle=True, num_workers=2)\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transf)\n",
    "testloader = DataLoader(testset, batch_size=8, shuffle=True, num_workers=2)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Net(nn.Module):\n",
    "    # 1. 연산셋팅\n",
    "    def __init__(self): \n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3,6,5)\n",
    "        self.pool = nn.MaxPool2d(2,2)\n",
    "        self.conv2 = nn.Conv2d(6,16,5)\n",
    "        self.fc1 = nn.Linear(16*5*5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10) # output이 10개의 종류로 나옴\n",
    "\n",
    "    # 2. 연산순서정의        \n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 16*5*5) # fully connected 에 넣기위해 1자로 피는 작업임\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "    \n",
    "net = Net() # class에 대한 instance 생성 model = Model() 딱 이거랑 같은거임"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (conv1): Conv2d(3, 6, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (fc1): Linear(in_features=400, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(net)\n",
    "# 32  -> 28 -> 14 -> 10 -> 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implement the model with training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "# 1. 손실함수 정의\n",
    "loss_function = nn.CrossEntropyLoss() # 분류문제에서 흔히쓰이는 loss function\n",
    "# 2. optimizer 정의\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9) # net.parameters() : 위의 instance에 쓰이는 모든 파라미터들 의미"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,  2000] loss : 1.408\n",
      "[1,  4000] loss : 1.382\n",
      "[1,  6000] loss : 1.332\n",
      "[2,  2000] loss : 1.266\n",
      "[2,  4000] loss : 1.224\n",
      "[2,  6000] loss : 1.216\n",
      "[3,  2000] loss : 1.158\n",
      "[3,  4000] loss : 1.141\n",
      "[3,  6000] loss : 1.124\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "epoch_num = 3 # 'epoch_num' : 전체를 몇 회독 할 것이냐는 의미\n",
    "for epoch in range(epoch_num) :\n",
    "    \n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0): # trainloader : 이 안에 이미지 8장씩 있음\n",
    "        \n",
    "        images, labels = data\n",
    "        \n",
    "        # paramerter 0으로 초기설정\n",
    "        optimizer.zero_grad() \n",
    "        \n",
    "        outputs = net(images) # 이 images가 forward에서 x가 되는셈!!\n",
    "        loss = loss_function(outputs, labels) # 배치 사이즈 8장에 대한 loss값(스칼라)\n",
    "        loss.backward() # loss기준으로 backward\n",
    "        optimizer.step() # opmizer 계산한다\n",
    "        \n",
    "        # print log\n",
    "        running_loss += loss.item() # 이렇게 하면 스칼라값 표현가능\n",
    "        if i % 2000 == 1999:\n",
    "            # print every 2000 mini-batches\n",
    "            print('[%d, %5d] loss : %.3f' %\n",
    "                  (epoch +1, i + 1, running_loss / 2000))\n",
    "            running_loss = 0.0\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 위의 SGD에서는 lr이 고정되어있음\n",
    "- 이때 scheduler라는걸 사용할 수 있음\n",
    "```\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr = 0.1, momentum = 0.9)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=30, gamma=0.1) # batch 30번마다 lr *= 0.1 하겠단거임\n",
    "\n",
    "for epoch in range(epoch_num)\n",
    "    pass\n",
    "    for data in trainloader :\n",
    "        pass\n",
    "    scheduler.step() # 이렇게 epoch에 대한 for문에 넣어야함. for문 위치 주의\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the trained model\n",
    "- path = ''\n",
    "- torch.save(net.state_dict(), path)\n",
    "\n",
    "### Load the pre-trained model\n",
    "- net = Net()\n",
    "- net.load_state_dict(torch.load(path))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict test data\n",
    "- output은 미니배치의 결과가 산출되는 것이므로 for문을 통해서 test 전체의 예측값을 구해야 함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuaracy of the network on the 10,000 test images : 58 %\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad() : # test data 는 gradient update를 안하므로\n",
    "    for data in testloader :\n",
    "        images, labels = data\n",
    "        outputs = net(images) # outputs : 10개의 값이 담겨있는 벡터\n",
    "        _, predicted = torch.max(outputs.data, 1) # 그 중 가장 큰 값을 고른다\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print('Accuaracy of the network on the 10,000 test images : %d %%' % (\n",
    "    100 * correct / total))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('kotorch')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e394b0e5950b2ed9ac02d3d0f43da50df004fa03f183c9ffe2862d4a06a95d21"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
