{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as tr # 데이터불러오면서 전처리까지 할 수 있음\n",
    "from torch.utils.data import DataLoader, Dataset # 배치 사이즈 만들어줌 / 데이터 튜닝\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. 파이토치 제공 데이터 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "transf = tr.Compose([tr.Resize(8),tr.ToTensor()])\n",
    "# 전처리 방법 'transf' 대해서 정의하는거임 : 8*8 resize 후에 Tensor로 바꿔주겠다는 것\n",
    "# 하지만 이렇게 하기위해선 입력받은 이미지가 PIL 이여야 해서 임의로 정의해줘야 하는 경우가 많음"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "내장 데이터 다운받기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transf)\n",
    "# ./data 위치에 CIFAR10 의 train 데이터를 transf 전처리 방법으로 다운로드 받겠다는 것\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 8, 8])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainset[0][0].size() # 기존과 다르게 channel 수가 제일 앞에 나옴 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# batch size 50개, sub process 2개로 진행한다\n",
    "trainloader = DataLoader(trainset, batch_size=50, shuffle=True, num_workers=2)\n",
    "testloader = DataLoader(testset, batch_size=50, shuffle=True, num_workers=2)\n",
    "len(trainloader) # trainset이 총 50,000개인데 50으로 나누어 총 1,000개가 있음! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([50, 3, 8, 8])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "detaiter = iter(trainloader)\n",
    "images, labels = detaiter.next()\n",
    "images.size() # batch, channel, size 순서!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**-> tensor와 ndarray는 순서가 다름!!**\n",
    "- tensor는 channel이 batch 다음임\n",
    "- ndarray는 channel이 제일 마지막"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. 개인 데이터 사용하기 - 1) 같은 클래스 별 폴더 이미지 데이터 사용"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 클래스 별 다르게 저장되어 있다고 가정 : ./class/tiger & ./class/lion 이런식"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\ntransf = tr.Compose([tr.Resize(16), tr.ToTensor()])\\ntrainset = torchvision.datasets.ImageFolder(root='./class', transform=transf)\\ntrainloader = DataLoader(trainset, batch_size=10, shuffle=False, num_workers=2)\\n-> 이렇게만으로 데이터도 불러오고 레이블 자동으로 매겨지고 전처리까지 되는거임!\\n\""
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "transf = tr.Compose([tr.Resize(16), tr.ToTensor()])\n",
    "trainset = torchvision.datasets.ImageFolder(root='./class', transform=transf)\n",
    "trainloader = DataLoader(trainset, batch_size=10, shuffle=False, num_workers=2)\n",
    "-> 이렇게만으로 데이터도 불러오고 레이블 자동으로 매겨지고 전처리까지 되는거임!\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. 개인 데이터 사용 - 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "방법 1.\n",
    "- 위의 방법의 경우 디렉토리를 함부러 건드리기 애매한경우나 폴더 단위가 아닌 sql로 받아오는 경우 등에는 사용불가\n",
    "- pytorch의 transform이 제한적이라 디테일은 직접 작성해줘야할 필요가 있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20, 32, 32, 3) \t (20, 1)\n"
     ]
    }
   ],
   "source": [
    "train_images = np.random.randint(256, size=(20,32,32,3)) # ndarray는 32*32 사이즈 3 channel 20개\n",
    "train_labels = np.random.randint(2, size=(20,1)) # 그에 따른 label도 20개\n",
    "'''\n",
    "그리고 class 객체 만들기 전에 여기서 preprocessing 과정을 거침\n",
    "train_images, train_labels = preprocessing(train_images, train_labels) 이런식으로\n",
    "'''\n",
    "print(train_images.shape, '\\t', train_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "* 정형화됨 *\n",
    "'Dataset'을 상속받으면서\n",
    "'__init__', '__getiem__', '__len_'\n",
    "을 갖는 class를 하나 만든다\n",
    "'''\n",
    "\n",
    "class TensorData(Dataset) :\n",
    "    \n",
    "    def __init__(self, x_data, y_data):\n",
    "        self.x_data = torch.FloatTensor(x_data) # x_data를 float유형의 tensor로 변경함\n",
    "        self.x_data = self.x_data.permute(0,3,1,2) # 기존 순서에서 순서를 변경해주는거임 : 총 개수, 채널 수, width, height\n",
    "        self.y_data = torch.LongTensor(y_data) # y_data도 long 유형의 tensor로 변경\n",
    "        self.len = self.y_data.shape[0]\n",
    "        \n",
    "    def __getitem__(self, index) :\n",
    "        sample = self.x_data[index], self.y_data[index] # 그 index에 해당하는 값을 튜플로 반환하는 함수\n",
    "        return sample\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. class 객체를 만들어준다\n",
    "train_data = TensorData(train_images, train_labels)\n",
    "# 2. 이를 DataLoader에 통과시켜서 batch 단위로 만들어준다\n",
    "train_loader = DataLoader(train_data, batch_size=10, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 32, 32])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[0][0].size() # 순서가 변경됨!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "방법2.\n",
    "- transform 기능 더하기! => transform에 대한 필요한 class 들을 다 작성하는 것임!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0. tensor로 바꾸는 기능을 별도의 class 함수로 빼고 transform 할지 여부를 init 함수에 포함한다\n",
    "# 1. transofrm을 한다고하면 그냥 튜플 내보내기전에 transform을 하고 튜플을 return 한다\n",
    "# 2. 이 튜플을 ToTensor로 받아서 tensor 형태로 바꾸어 준다\n",
    "\n",
    "class MyDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, x_data, y_data, transform = None):\n",
    "        '''\n",
    "        self.x_data = torch.FloatTensor(x_data) \n",
    "        self.x_data = self.x_data.permute(0,3,1,2)\n",
    "        self.y_data = torch.LongTensor(y_data) \n",
    "        '''\n",
    "        self.x_data = x_data\n",
    "        self.y_data = y_data\n",
    "        self.transform = transform\n",
    "        self.len = self.y_data.shape[0]\n",
    "        \n",
    "    def __getitem__(self, index) :\n",
    "        sample = self.x_data[index], self.y_data[index] # 그 index에 해당하는 값을 튜플로 반환하는 함수\n",
    "        \n",
    "        if self.transform :\n",
    "            sample = self.transform(sample)\n",
    "            \n",
    "        return sample\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "    \n",
    "class ToTensor_customed:\n",
    "    \n",
    "    def __call__(self, sample):\n",
    "        inputs, labels = sample # sample 이 튜플 형태니까 이렇게 받을 수 있음\n",
    "        # 여기에서 tensor로 바꾸고 순서 바꾸는 작업 수행\n",
    "        inputs = torch.FloatTensor(inputs)\n",
    "        inputs = inputs.permute(2,0,1)\n",
    "        labels = torch.LongTensor(labels)\n",
    "        return inputs, labels\n",
    "    \n",
    "# 그리고 지금 할 연산 관련 class까지\n",
    "class LinearTensor :\n",
    "    \n",
    "    def __init__(self, weight=1, bias=0):\n",
    "        self.weight = weight\n",
    "        self.bias = bias\n",
    "        \n",
    "    def __call__(self, sample):\n",
    "        inputs, labels = sample\n",
    "        inputs = self.weight*inputs + self.bias\n",
    "        return inputs, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "trans = tr.Compose([ToTensor_customed(), LinearTensor(2,5)]) # tensor 바꾸기 위해 trans 정의할때 여기서 사용\n",
    "\n",
    "train_images = np.random.randint(256, size=(20,32,32,3)) # ndarray는 32*32 사이즈 3 channel 20개\n",
    "train_labels = np.random.randint(2, size=(20,1)) # 그에 따른 label도 20개\n",
    "\n",
    "ds1 = MyDataset(train_images, train_labels, transform=trans)\n",
    "\n",
    "train_loader1 = DataLoader(ds1, batch_size=10, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'> <class 'torch.Tensor'>\n"
     ]
    }
   ],
   "source": [
    "first_data = ds1[0]\n",
    "features, labels = first_data\n",
    "print(type(features), type(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[165., 107., 345.,  ...,  75., 459., 395.],\n",
       "          [481., 161., 117.,  ..., 107., 421., 231.],\n",
       "          [121., 197., 227.,  ..., 301., 335., 185.],\n",
       "          ...,\n",
       "          [387., 177.,  47.,  ..., 155., 339., 315.],\n",
       "          [447., 433.,  37.,  ..., 391., 383., 233.],\n",
       "          [389., 355., 317.,  ..., 293., 107., 457.]],\n",
       "\n",
       "         [[309., 157., 323.,  ...,  61., 453., 267.],\n",
       "          [207., 201., 253.,  ..., 489., 321., 167.],\n",
       "          [275.,  21., 463.,  ...,  87., 317., 215.],\n",
       "          ...,\n",
       "          [ 45., 147.,  57.,  ..., 437.,  13., 323.],\n",
       "          [  5., 105., 195.,  ..., 355., 319., 169.],\n",
       "          [363., 425., 211.,  ...,  79., 315., 391.]],\n",
       "\n",
       "         [[399., 217., 267.,  ..., 411.,  61., 471.],\n",
       "          [ 61., 255., 157.,  ...,  57., 257., 513.],\n",
       "          [ 57., 321., 409.,  ..., 105., 453., 157.],\n",
       "          ...,\n",
       "          [ 21., 235., 365.,  ...,  91.,  19.,  15.],\n",
       "          [265., 257., 387.,  ...,  29., 451., 257.],\n",
       "          [101., 187.,  49.,  ..., 105., 513., 109.]]],\n",
       "\n",
       "\n",
       "        [[[449., 413., 471.,  ..., 451., 103., 285.],\n",
       "          [221., 283., 257.,  ..., 467.,  19., 233.],\n",
       "          [ 13., 143., 475.,  ..., 163.,  31., 229.],\n",
       "          ...,\n",
       "          [137.,  23., 307.,  ..., 271., 477., 269.],\n",
       "          [411., 267., 507.,  ..., 373., 397., 325.],\n",
       "          [405., 145., 165.,  ..., 407., 109., 263.]],\n",
       "\n",
       "         [[177.,   5., 447.,  ..., 353., 483., 285.],\n",
       "          [373., 235.,  11.,  ..., 403.,  27., 161.],\n",
       "          [411., 249.,  67.,  ..., 263., 435., 501.],\n",
       "          ...,\n",
       "          [461., 399., 287.,  ...,  37., 215., 245.],\n",
       "          [ 87.,  89., 515.,  ..., 113., 231.,  95.],\n",
       "          [ 37., 499., 165.,  ..., 319., 397., 413.]],\n",
       "\n",
       "         [[415., 427.,  27.,  ..., 371., 255., 147.],\n",
       "          [223., 283.,  57.,  ...,  59., 249.,  27.],\n",
       "          [301., 189.,  49.,  ..., 153., 157., 327.],\n",
       "          ...,\n",
       "          [293.,  27., 361.,  ..., 309.,  77., 293.],\n",
       "          [ 55., 253., 365.,  ...,  47.,  41.,  95.],\n",
       "          [377., 407.,  35.,  ..., 271., 511., 229.]]],\n",
       "\n",
       "\n",
       "        [[[ 85., 315., 241.,  ..., 135., 179., 359.],\n",
       "          [377.,  61., 177.,  ..., 467.,  33., 185.],\n",
       "          [445., 141., 319.,  ...,   5., 413., 489.],\n",
       "          ...,\n",
       "          [285., 383.,  25.,  ...,  83.,  67., 359.],\n",
       "          [ 63., 201., 337.,  ..., 497.,  57., 301.],\n",
       "          [ 55., 261., 269.,  ..., 409., 355.,  77.]],\n",
       "\n",
       "         [[453., 269.,  89.,  ..., 399.,  49., 495.],\n",
       "          [121., 217., 387.,  ..., 185., 123., 187.],\n",
       "          [205., 169., 111.,  ..., 243.,  11., 281.],\n",
       "          ...,\n",
       "          [215., 489., 313.,  ..., 421., 293., 321.],\n",
       "          [269., 299., 199.,  ..., 311.,  87., 397.],\n",
       "          [479., 115., 155.,  ..., 513.,  31., 301.]],\n",
       "\n",
       "         [[217., 321., 513.,  ...,   5., 109., 419.],\n",
       "          [365., 513., 225.,  ..., 245., 323., 245.],\n",
       "          [129.,  69., 327.,  ...,   7., 249., 303.],\n",
       "          ...,\n",
       "          [223., 455., 183.,  ..., 113., 335., 413.],\n",
       "          [239.,  75.,  49.,  ..., 427., 353., 415.],\n",
       "          [267., 111., 405.,  ...,  45., 229., 507.]]],\n",
       "\n",
       "\n",
       "        ...,\n",
       "\n",
       "\n",
       "        [[[475., 335., 435.,  ..., 273.,  21.,  85.],\n",
       "          [137., 253., 271.,  ..., 475., 421.,  23.],\n",
       "          [403.,  57., 207.,  ..., 245.,  57., 271.],\n",
       "          ...,\n",
       "          [347., 347., 419.,  ..., 247., 343., 375.],\n",
       "          [301., 277., 281.,  ..., 325., 321., 113.],\n",
       "          [ 59., 419., 355.,  ..., 277., 457., 151.]],\n",
       "\n",
       "         [[505.,  69., 247.,  ..., 193., 455., 303.],\n",
       "          [ 81., 451.,  71.,  ..., 339., 105.,  87.],\n",
       "          [ 95., 373.,  17.,  ..., 381., 265., 309.],\n",
       "          ...,\n",
       "          [427.,  75., 433.,  ..., 313., 299., 147.],\n",
       "          [267., 315., 301.,  ..., 243., 191.,  83.],\n",
       "          [ 81., 419., 283.,  ...,  49., 205., 501.]],\n",
       "\n",
       "         [[305.,  75., 225.,  ...,  17., 373., 327.],\n",
       "          [283., 473., 203.,  ..., 191., 439., 145.],\n",
       "          [191.,  23., 429.,  ..., 447., 259., 287.],\n",
       "          ...,\n",
       "          [ 13., 307., 371.,  ...,   9., 115., 149.],\n",
       "          [497.,  61., 205.,  ..., 455., 365., 219.],\n",
       "          [325., 209.,  47.,  ..., 275., 315.,  37.]]],\n",
       "\n",
       "\n",
       "        [[[123., 493., 499.,  ..., 367., 401., 357.],\n",
       "          [121., 365.,  45.,  ..., 473., 205., 301.],\n",
       "          [449.,  39., 111.,  ..., 199., 271., 389.],\n",
       "          ...,\n",
       "          [403., 343., 255.,  ..., 489.,   7., 247.],\n",
       "          [195., 279., 295.,  ..., 265., 231., 133.],\n",
       "          [387., 511., 437.,  ..., 369.,  33., 259.]],\n",
       "\n",
       "         [[213., 461., 269.,  ..., 369., 435.,  89.],\n",
       "          [507.,  71., 203.,  ..., 479., 383.,  49.],\n",
       "          [117., 359., 213.,  ..., 373., 317., 327.],\n",
       "          ...,\n",
       "          [ 67., 513., 497.,  ..., 407.,  89., 119.],\n",
       "          [115., 491., 373.,  ..., 315.,  27., 247.],\n",
       "          [309., 203.,  75.,  ..., 431., 499., 307.]],\n",
       "\n",
       "         [[289., 289., 431.,  ..., 413., 491., 387.],\n",
       "          [471., 375., 209.,  ..., 279., 467., 317.],\n",
       "          [123., 169., 441.,  ...,  57., 335., 119.],\n",
       "          ...,\n",
       "          [ 75., 147., 277.,  ..., 373., 115., 411.],\n",
       "          [ 75., 213.,  43.,  ..., 453., 397., 361.],\n",
       "          [361., 167., 295.,  ..., 109., 443., 501.]]],\n",
       "\n",
       "\n",
       "        [[[143., 419., 255.,  ...,  21., 461., 365.],\n",
       "          [ 11., 171.,  47.,  ..., 287., 131., 157.],\n",
       "          [185.,  37.,  79.,  ..., 327., 379., 143.],\n",
       "          ...,\n",
       "          [453., 437., 195.,  ..., 429., 301., 343.],\n",
       "          [205., 431., 425.,  ..., 353., 273., 101.],\n",
       "          [393., 187., 301.,  ..., 177., 121., 121.]],\n",
       "\n",
       "         [[173., 191., 157.,  ..., 439., 341.,  31.],\n",
       "          [181., 161., 323.,  ..., 203., 491., 479.],\n",
       "          [417.,  49., 461.,  ..., 435., 287., 159.],\n",
       "          ...,\n",
       "          [235., 271., 375.,  ...,  85., 293., 241.],\n",
       "          [387., 337., 193.,  ...,  87.,  81., 395.],\n",
       "          [133., 485., 167.,  ..., 315., 179., 389.]],\n",
       "\n",
       "         [[ 73.,  21., 131.,  ..., 463.,  19., 317.],\n",
       "          [441.,  93.,  29.,  ...,  81., 325., 367.],\n",
       "          [127.,  13.,  61.,  ..., 105., 247., 177.],\n",
       "          ...,\n",
       "          [203.,  77., 377.,  ..., 139., 223., 231.],\n",
       "          [357., 321., 247.,  ..., 215., 127., 379.],\n",
       "          [113., 331., 467.,  ..., 371., 217.,  39.]]]])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataiter1= iter(train_loader1)\n",
    "images1, labels1 = dataiter1.next()\n",
    "images1 # r값 분포가 0 ~ 255 여야 하는데 넘어가는 걸 보니 정상적으로 된 것을 알 수있음"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('kotorch')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e394b0e5950b2ed9ac02d3d0f43da50df004fa03f183c9ffe2862d4a06a95d21"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
