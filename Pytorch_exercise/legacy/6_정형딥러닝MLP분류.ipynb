{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP를 통한 부산항 미세먼지 예측\n",
    "- 산업데이터 과학 수업 데이터\n",
    "- PM2만 예측하는거임 (task => 다중분류 : 레이블 3개 => 0,1,2 로 타겟값 분류)\n",
    "- 내가갖고있는 정형데이터를 pytorch에 어떻게 적용하는지 싶을떄 보면 좋음!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PM</th>\n",
       "      <th>PM2</th>\n",
       "      <th>EG1</th>\n",
       "      <th>EG2</th>\n",
       "      <th>EG3</th>\n",
       "      <th>EG4</th>\n",
       "      <th>EG5</th>\n",
       "      <th>EG6</th>\n",
       "      <th>EG7</th>\n",
       "      <th>EG8</th>\n",
       "      <th>...</th>\n",
       "      <th>EG15</th>\n",
       "      <th>EG16</th>\n",
       "      <th>EG17</th>\n",
       "      <th>EG18</th>\n",
       "      <th>EG19</th>\n",
       "      <th>EG20</th>\n",
       "      <th>HUM</th>\n",
       "      <th>TMP</th>\n",
       "      <th>WD</th>\n",
       "      <th>WS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>27.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>1305.26</td>\n",
       "      <td>15069.82</td>\n",
       "      <td>12815.28</td>\n",
       "      <td>2847.84</td>\n",
       "      <td>2847.84</td>\n",
       "      <td>1230.46</td>\n",
       "      <td>14206.22</td>\n",
       "      <td>12080.88</td>\n",
       "      <td>...</td>\n",
       "      <td>636.48</td>\n",
       "      <td>583.44</td>\n",
       "      <td>6736.08</td>\n",
       "      <td>5728.32</td>\n",
       "      <td>1272.96</td>\n",
       "      <td>1272.96</td>\n",
       "      <td>91</td>\n",
       "      <td>7.2</td>\n",
       "      <td>0.906308</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>52.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>1021.02</td>\n",
       "      <td>11788.14</td>\n",
       "      <td>10024.56</td>\n",
       "      <td>2227.68</td>\n",
       "      <td>2227.68</td>\n",
       "      <td>729.30</td>\n",
       "      <td>8420.10</td>\n",
       "      <td>7160.40</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>437.58</td>\n",
       "      <td>5052.06</td>\n",
       "      <td>4296.24</td>\n",
       "      <td>954.72</td>\n",
       "      <td>954.72</td>\n",
       "      <td>36</td>\n",
       "      <td>14.3</td>\n",
       "      <td>0.438371</td>\n",
       "      <td>1.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>22.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>867.68</td>\n",
       "      <td>10017.76</td>\n",
       "      <td>8519.04</td>\n",
       "      <td>1893.12</td>\n",
       "      <td>1893.12</td>\n",
       "      <td>1301.52</td>\n",
       "      <td>15026.64</td>\n",
       "      <td>12778.56</td>\n",
       "      <td>...</td>\n",
       "      <td>318.24</td>\n",
       "      <td>291.72</td>\n",
       "      <td>3368.04</td>\n",
       "      <td>2864.16</td>\n",
       "      <td>636.48</td>\n",
       "      <td>636.48</td>\n",
       "      <td>38</td>\n",
       "      <td>6.7</td>\n",
       "      <td>0.992546</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>23.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>729.30</td>\n",
       "      <td>8420.10</td>\n",
       "      <td>7160.40</td>\n",
       "      <td>1591.20</td>\n",
       "      <td>1591.20</td>\n",
       "      <td>729.30</td>\n",
       "      <td>8420.10</td>\n",
       "      <td>7160.40</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>145.86</td>\n",
       "      <td>1684.02</td>\n",
       "      <td>1432.08</td>\n",
       "      <td>318.24</td>\n",
       "      <td>318.24</td>\n",
       "      <td>23</td>\n",
       "      <td>9.7</td>\n",
       "      <td>0.241922</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>90.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>946.22</td>\n",
       "      <td>10924.54</td>\n",
       "      <td>9290.16</td>\n",
       "      <td>2064.48</td>\n",
       "      <td>2064.48</td>\n",
       "      <td>575.96</td>\n",
       "      <td>6649.72</td>\n",
       "      <td>5654.88</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>583.44</td>\n",
       "      <td>6736.08</td>\n",
       "      <td>5728.32</td>\n",
       "      <td>1272.96</td>\n",
       "      <td>1272.96</td>\n",
       "      <td>18</td>\n",
       "      <td>5.9</td>\n",
       "      <td>0.484810</td>\n",
       "      <td>1.3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     PM   PM2      EG1       EG2       EG3      EG4      EG5      EG6  \\\n",
       "0  27.0  25.0  1305.26  15069.82  12815.28  2847.84  2847.84  1230.46   \n",
       "1  52.0  17.0  1021.02  11788.14  10024.56  2227.68  2227.68   729.30   \n",
       "2  22.0  12.0   867.68  10017.76   8519.04  1893.12  1893.12  1301.52   \n",
       "3  23.0  13.0   729.30   8420.10   7160.40  1591.20  1591.20   729.30   \n",
       "4  90.0  63.0   946.22  10924.54   9290.16  2064.48  2064.48   575.96   \n",
       "\n",
       "        EG7       EG8  ...    EG15    EG16     EG17     EG18     EG19  \\\n",
       "0  14206.22  12080.88  ...  636.48  583.44  6736.08  5728.32  1272.96   \n",
       "1   8420.10   7160.40  ...    0.00  437.58  5052.06  4296.24   954.72   \n",
       "2  15026.64  12778.56  ...  318.24  291.72  3368.04  2864.16   636.48   \n",
       "3   8420.10   7160.40  ...    0.00  145.86  1684.02  1432.08   318.24   \n",
       "4   6649.72   5654.88  ...    0.00  583.44  6736.08  5728.32  1272.96   \n",
       "\n",
       "      EG20  HUM   TMP        WD   WS  \n",
       "0  1272.96   91   7.2  0.906308  0.6  \n",
       "1   954.72   36  14.3  0.438371  1.3  \n",
       "2   636.48   38   6.7  0.992546  0.5  \n",
       "3   318.24   23   9.7  0.241922  3.0  \n",
       "4  1272.96   18   5.9  0.484810  1.3  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = r'C:\\Users\\SeoJeongBin\\Desktop\\Code\\Pytorch\\Pytorch_exercise\\data\\iudustrial_science\\fine_dust.csv'\n",
    "df = pd.read_csv(path)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PM</th>\n",
       "      <th>PM2</th>\n",
       "      <th>EG1</th>\n",
       "      <th>EG2</th>\n",
       "      <th>EG3</th>\n",
       "      <th>EG4</th>\n",
       "      <th>EG5</th>\n",
       "      <th>EG6</th>\n",
       "      <th>EG7</th>\n",
       "      <th>EG8</th>\n",
       "      <th>...</th>\n",
       "      <th>EG15</th>\n",
       "      <th>EG16</th>\n",
       "      <th>EG17</th>\n",
       "      <th>EG18</th>\n",
       "      <th>EG19</th>\n",
       "      <th>EG20</th>\n",
       "      <th>HUM</th>\n",
       "      <th>TMP</th>\n",
       "      <th>WD</th>\n",
       "      <th>WS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>27.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1305.26</td>\n",
       "      <td>15069.82</td>\n",
       "      <td>12815.28</td>\n",
       "      <td>2847.84</td>\n",
       "      <td>2847.84</td>\n",
       "      <td>1230.46</td>\n",
       "      <td>14206.22</td>\n",
       "      <td>12080.88</td>\n",
       "      <td>...</td>\n",
       "      <td>636.48</td>\n",
       "      <td>583.44</td>\n",
       "      <td>6736.08</td>\n",
       "      <td>5728.32</td>\n",
       "      <td>1272.96</td>\n",
       "      <td>1272.96</td>\n",
       "      <td>91</td>\n",
       "      <td>7.2</td>\n",
       "      <td>0.906308</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>52.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1021.02</td>\n",
       "      <td>11788.14</td>\n",
       "      <td>10024.56</td>\n",
       "      <td>2227.68</td>\n",
       "      <td>2227.68</td>\n",
       "      <td>729.30</td>\n",
       "      <td>8420.10</td>\n",
       "      <td>7160.40</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>437.58</td>\n",
       "      <td>5052.06</td>\n",
       "      <td>4296.24</td>\n",
       "      <td>954.72</td>\n",
       "      <td>954.72</td>\n",
       "      <td>36</td>\n",
       "      <td>14.3</td>\n",
       "      <td>0.438371</td>\n",
       "      <td>1.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>22.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>867.68</td>\n",
       "      <td>10017.76</td>\n",
       "      <td>8519.04</td>\n",
       "      <td>1893.12</td>\n",
       "      <td>1893.12</td>\n",
       "      <td>1301.52</td>\n",
       "      <td>15026.64</td>\n",
       "      <td>12778.56</td>\n",
       "      <td>...</td>\n",
       "      <td>318.24</td>\n",
       "      <td>291.72</td>\n",
       "      <td>3368.04</td>\n",
       "      <td>2864.16</td>\n",
       "      <td>636.48</td>\n",
       "      <td>636.48</td>\n",
       "      <td>38</td>\n",
       "      <td>6.7</td>\n",
       "      <td>0.992546</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>23.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>729.30</td>\n",
       "      <td>8420.10</td>\n",
       "      <td>7160.40</td>\n",
       "      <td>1591.20</td>\n",
       "      <td>1591.20</td>\n",
       "      <td>729.30</td>\n",
       "      <td>8420.10</td>\n",
       "      <td>7160.40</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>145.86</td>\n",
       "      <td>1684.02</td>\n",
       "      <td>1432.08</td>\n",
       "      <td>318.24</td>\n",
       "      <td>318.24</td>\n",
       "      <td>23</td>\n",
       "      <td>9.7</td>\n",
       "      <td>0.241922</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>90.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>946.22</td>\n",
       "      <td>10924.54</td>\n",
       "      <td>9290.16</td>\n",
       "      <td>2064.48</td>\n",
       "      <td>2064.48</td>\n",
       "      <td>575.96</td>\n",
       "      <td>6649.72</td>\n",
       "      <td>5654.88</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>583.44</td>\n",
       "      <td>6736.08</td>\n",
       "      <td>5728.32</td>\n",
       "      <td>1272.96</td>\n",
       "      <td>1272.96</td>\n",
       "      <td>18</td>\n",
       "      <td>5.9</td>\n",
       "      <td>0.484810</td>\n",
       "      <td>1.3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     PM  PM2      EG1       EG2       EG3      EG4      EG5      EG6  \\\n",
       "0  27.0  1.0  1305.26  15069.82  12815.28  2847.84  2847.84  1230.46   \n",
       "1  52.0  1.0  1021.02  11788.14  10024.56  2227.68  2227.68   729.30   \n",
       "2  22.0  0.0   867.68  10017.76   8519.04  1893.12  1893.12  1301.52   \n",
       "3  23.0  0.0   729.30   8420.10   7160.40  1591.20  1591.20   729.30   \n",
       "4  90.0  2.0   946.22  10924.54   9290.16  2064.48  2064.48   575.96   \n",
       "\n",
       "        EG7       EG8  ...    EG15    EG16     EG17     EG18     EG19  \\\n",
       "0  14206.22  12080.88  ...  636.48  583.44  6736.08  5728.32  1272.96   \n",
       "1   8420.10   7160.40  ...    0.00  437.58  5052.06  4296.24   954.72   \n",
       "2  15026.64  12778.56  ...  318.24  291.72  3368.04  2864.16   636.48   \n",
       "3   8420.10   7160.40  ...    0.00  145.86  1684.02  1432.08   318.24   \n",
       "4   6649.72   5654.88  ...    0.00  583.44  6736.08  5728.32  1272.96   \n",
       "\n",
       "      EG20  HUM   TMP        WD   WS  \n",
       "0  1272.96   91   7.2  0.906308  0.6  \n",
       "1   954.72   36  14.3  0.438371  1.3  \n",
       "2   636.48   38   6.7  0.992546  0.5  \n",
       "3   318.24   23   9.7  0.241922  3.0  \n",
       "4  1272.96   18   5.9  0.484810  1.3  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# PM2를 등급별로 새로 레이블 매기기\n",
    "\n",
    "idx0 = df.loc[df['PM2']<=15,:].index # 이러면 행 번호가 나옴\n",
    "idx1 = df.loc[(df['PM2']>=15) & (df['PM2']<=35),:].index\n",
    "idx2 = df.loc[(df['PM2']>=36),:].index\n",
    "\n",
    "df.iloc[idx0,1] = 0\n",
    "df.iloc[idx1,1] = 1\n",
    "df.iloc[idx2,1] = 2\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 셋 분류\n",
    "x = df.iloc[:,2:]\n",
    "y = df.iloc[:, 1]\n",
    "\n",
    "# x : 정규화 수행\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "min_max_scaler = MinMaxScaler()\n",
    "min_max_scaler.fit(x)\n",
    "x = min_max_scaler.transform(x)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "trainx, validx, trainy, validy = train_test_split(x, y, test_size=0.3, random_state = 15)\n",
    "\n",
    "# x : torch tensor로 타입 변경\n",
    "trainx = torch.FloatTensor(trainx)\n",
    "validx = torch.FloatTensor(validx)\n",
    "\n",
    "# y : torch tensor로 타입 변경\n",
    "trainy = torch.FloatTensor(trainy.values).view(-1)\n",
    "trainy = trainy.long()\n",
    "\n",
    "validy = torch.FloatTensor(validy.values).view(-1)\n",
    "validy = validy.long()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class myMLP(nn.Module):\n",
    "    def __init__(self, input_size) : # 여기 같은경우엔 인자로 input size를 받네\n",
    "        super(myMLP, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Linear(self.input_size, 18),\n",
    "            torch.nn.BatchNorm1d(18), # 배치정규화 좀 알아보기\n",
    "            nn.Linear(18, 9),\n",
    "            torch.nn.BatchNorm1d(9),\n",
    "            nn.Linear(9, 3), # 3 : 예측해야할 레이블 수\n",
    "            torch.nn.ReLU()\n",
    "        )\n",
    "        self.layer2 = torch.nn.Dropout()\n",
    "        self.layer3 = torch.nn.Softmax()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        output = self.layer1(x)\n",
    "        output = self.layer2(output)\n",
    "        output = self.layer3(output)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 선언\n",
    "# trainx.size() : torch.Size([2399, 24])\n",
    "input_size = trainx.size()[1] # ★ mlp 모양에서 각 노드가 칼럼이 되는셈이라 칼럼개수가 input size다!!!!!!!!\n",
    "model = myMLP(input_size)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "loss = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoJeongBin\\AppData\\Local\\Temp\\ipykernel_5428\\1789303409.py:19: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  output = self.layer3(output)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch: 1000/10000] [Loss: 1.041819] [valid Accuracy: 51.797862]\n",
      "[Epoch: 2000/10000] [Loss: 0.969562] [valid Accuracy: 57.628766]\n",
      "[Epoch: 3000/10000] [Loss: 0.969188] [valid Accuracy: 57.920311]\n",
      "[Epoch: 4000/10000] [Loss: 0.969029] [valid Accuracy: 58.017493]\n",
      "[Epoch: 5000/10000] [Loss: 0.968922] [valid Accuracy: 57.725948]\n",
      "[Epoch: 6000/10000] [Loss: 0.968698] [valid Accuracy: 57.920311]\n",
      "[Epoch: 7000/10000] [Loss: 0.968776] [valid Accuracy: 57.628766]\n",
      "[Epoch: 8000/10000] [Loss: 0.968532] [valid Accuracy: 57.725948]\n",
      "[Epoch: 9000/10000] [Loss: 0.968331] [valid Accuracy: 57.531584]\n",
      "[Epoch: 10000/10000] [Loss: 0.968439] [valid Accuracy: 57.823129]\n"
     ]
    }
   ],
   "source": [
    "# 학습 돌리기\n",
    "epochs = 10000\n",
    "\n",
    "for e in range(epochs):\n",
    "    optimizer.zero_grad()\n",
    "    out = model(trainx)\n",
    "    L = loss(out,trainy)\n",
    "    L.backward()\n",
    "    optimizer.step()\n",
    "    if (e+1) % 1000 == 0:\n",
    "        with torch.no_grad():\n",
    "            model.eval()\n",
    "            pred = model(validx)\n",
    "            acc = sum(torch.max(pred,1)[1] == validy).numpy()/len(validy) # 이건 task가 분류임을 주의\n",
    "\n",
    "        print('[Epoch: {}/{}] [Loss: {:2f}] [valid Accuracy: {:2f}]'.format(e+1, epochs, L.item(), acc*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### test 데이터에 적용해보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EG1</th>\n",
       "      <th>EG2</th>\n",
       "      <th>EG3</th>\n",
       "      <th>EG4</th>\n",
       "      <th>EG5</th>\n",
       "      <th>EG6</th>\n",
       "      <th>EG7</th>\n",
       "      <th>EG8</th>\n",
       "      <th>EG9</th>\n",
       "      <th>EG10</th>\n",
       "      <th>...</th>\n",
       "      <th>EG15</th>\n",
       "      <th>EG16</th>\n",
       "      <th>EG17</th>\n",
       "      <th>EG18</th>\n",
       "      <th>EG19</th>\n",
       "      <th>EG20</th>\n",
       "      <th>HUM</th>\n",
       "      <th>TMP</th>\n",
       "      <th>WD</th>\n",
       "      <th>WS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>583.44</td>\n",
       "      <td>6736.08</td>\n",
       "      <td>5728.32</td>\n",
       "      <td>1272.96</td>\n",
       "      <td>1272.96</td>\n",
       "      <td>583.44</td>\n",
       "      <td>6736.08</td>\n",
       "      <td>5728.32</td>\n",
       "      <td>1272.96</td>\n",
       "      <td>1272.96</td>\n",
       "      <td>...</td>\n",
       "      <td>954.72</td>\n",
       "      <td>437.58</td>\n",
       "      <td>5052.06</td>\n",
       "      <td>4296.24</td>\n",
       "      <td>954.72</td>\n",
       "      <td>954.72</td>\n",
       "      <td>68</td>\n",
       "      <td>23.7</td>\n",
       "      <td>0.882948</td>\n",
       "      <td>0.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>875.16</td>\n",
       "      <td>10104.12</td>\n",
       "      <td>8592.48</td>\n",
       "      <td>1909.44</td>\n",
       "      <td>1909.44</td>\n",
       "      <td>1151.92</td>\n",
       "      <td>13299.44</td>\n",
       "      <td>11309.76</td>\n",
       "      <td>2513.28</td>\n",
       "      <td>2513.28</td>\n",
       "      <td>...</td>\n",
       "      <td>954.72</td>\n",
       "      <td>583.44</td>\n",
       "      <td>6736.08</td>\n",
       "      <td>5728.32</td>\n",
       "      <td>1272.96</td>\n",
       "      <td>1272.96</td>\n",
       "      <td>34</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0.190809</td>\n",
       "      <td>3.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>729.30</td>\n",
       "      <td>8420.10</td>\n",
       "      <td>7160.40</td>\n",
       "      <td>1591.20</td>\n",
       "      <td>1591.20</td>\n",
       "      <td>1092.08</td>\n",
       "      <td>12608.56</td>\n",
       "      <td>10722.24</td>\n",
       "      <td>2382.72</td>\n",
       "      <td>2382.72</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>437.58</td>\n",
       "      <td>5052.06</td>\n",
       "      <td>4296.24</td>\n",
       "      <td>954.72</td>\n",
       "      <td>954.72</td>\n",
       "      <td>58</td>\n",
       "      <td>11.9</td>\n",
       "      <td>0.754710</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>875.16</td>\n",
       "      <td>10104.12</td>\n",
       "      <td>8592.48</td>\n",
       "      <td>1909.44</td>\n",
       "      <td>1909.44</td>\n",
       "      <td>1600.72</td>\n",
       "      <td>18481.04</td>\n",
       "      <td>15716.16</td>\n",
       "      <td>3492.48</td>\n",
       "      <td>3492.48</td>\n",
       "      <td>...</td>\n",
       "      <td>954.72</td>\n",
       "      <td>291.72</td>\n",
       "      <td>3368.04</td>\n",
       "      <td>2864.16</td>\n",
       "      <td>636.48</td>\n",
       "      <td>636.48</td>\n",
       "      <td>25</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.275637</td>\n",
       "      <td>1.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1237.94</td>\n",
       "      <td>14292.58</td>\n",
       "      <td>12154.32</td>\n",
       "      <td>2700.96</td>\n",
       "      <td>2700.96</td>\n",
       "      <td>1806.42</td>\n",
       "      <td>20855.94</td>\n",
       "      <td>17735.76</td>\n",
       "      <td>3941.28</td>\n",
       "      <td>3941.28</td>\n",
       "      <td>...</td>\n",
       "      <td>636.48</td>\n",
       "      <td>1301.52</td>\n",
       "      <td>15026.64</td>\n",
       "      <td>12778.56</td>\n",
       "      <td>2839.68</td>\n",
       "      <td>2839.68</td>\n",
       "      <td>66</td>\n",
       "      <td>13.7</td>\n",
       "      <td>-0.173648</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       EG1       EG2       EG3      EG4      EG5      EG6       EG7       EG8  \\\n",
       "0   583.44   6736.08   5728.32  1272.96  1272.96   583.44   6736.08   5728.32   \n",
       "1   875.16  10104.12   8592.48  1909.44  1909.44  1151.92  13299.44  11309.76   \n",
       "2   729.30   8420.10   7160.40  1591.20  1591.20  1092.08  12608.56  10722.24   \n",
       "3   875.16  10104.12   8592.48  1909.44  1909.44  1600.72  18481.04  15716.16   \n",
       "4  1237.94  14292.58  12154.32  2700.96  2700.96  1806.42  20855.94  17735.76   \n",
       "\n",
       "       EG9     EG10  ...    EG15     EG16      EG17      EG18     EG19  \\\n",
       "0  1272.96  1272.96  ...  954.72   437.58   5052.06   4296.24   954.72   \n",
       "1  2513.28  2513.28  ...  954.72   583.44   6736.08   5728.32  1272.96   \n",
       "2  2382.72  2382.72  ...    0.00   437.58   5052.06   4296.24   954.72   \n",
       "3  3492.48  3492.48  ...  954.72   291.72   3368.04   2864.16   636.48   \n",
       "4  3941.28  3941.28  ...  636.48  1301.52  15026.64  12778.56  2839.68   \n",
       "\n",
       "      EG20  HUM   TMP        WD   WS  \n",
       "0   954.72   68  23.7  0.882948  0.7  \n",
       "1  1272.96   34   3.5  0.190809  3.5  \n",
       "2   954.72   58  11.9  0.754710  0.6  \n",
       "3   636.48   25   7.0  0.275637  1.9  \n",
       "4  2839.68   66  13.7 -0.173648  0.4  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = r'C:\\Users\\SeoJeongBin\\Desktop\\Code\\Pytorch\\Pytorch_exercise\\data\\iudustrial_science\\fine_dust_without_y.csv'\n",
    "df_test = pd.read_csv(path)\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = df_test \n",
    "# x : 정규화 수행\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "min_max_scaler = MinMaxScaler()\n",
    "min_max_scaler.fit(test)\n",
    "test = min_max_scaler.transform(test)\n",
    "\n",
    "# x : torch tensor로 타입 변경\n",
    "test = torch.FloatTensor(test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoJeongBin\\AppData\\Local\\Temp\\ipykernel_5428\\1789303409.py:19: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  output = self.layer3(output)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[1.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "        [1.6159e-24, 7.9719e-01, 2.0281e-01],\n",
       "        [1.9890e-16, 9.3983e-01, 6.0168e-02],\n",
       "        [3.8625e-31, 7.1422e-01, 2.8578e-01],\n",
       "        [7.5253e-24, 2.3910e-01, 7.6090e-01],\n",
       "        [4.9442e-23, 8.6994e-01, 1.3006e-01],\n",
       "        [1.2118e-18, 9.4340e-01, 5.6598e-02],\n",
       "        [2.9402e-23, 7.9291e-01, 2.0709e-01],\n",
       "        [7.2385e-37, 5.5710e-01, 4.4290e-01],\n",
       "        [7.9807e-31, 5.9586e-01, 4.0414e-01],\n",
       "        [1.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "        [7.2630e-37, 5.7520e-01, 4.2480e-01],\n",
       "        [8.8912e-39, 7.9767e-01, 2.0233e-01],\n",
       "        [2.5509e-34, 6.8258e-01, 3.1742e-01],\n",
       "        [3.2614e-18, 7.1989e-01, 2.8011e-01],\n",
       "        [2.2016e-28, 8.2890e-01, 1.7110e-01],\n",
       "        [1.3093e-23, 6.8736e-01, 3.1264e-01],\n",
       "        [2.2406e-16, 7.7740e-01, 2.2260e-01],\n",
       "        [4.0879e-15, 9.6767e-01, 3.2331e-02],\n",
       "        [1.0100e-32, 4.9796e-01, 5.0204e-01],\n",
       "        [8.5821e-19, 8.2738e-01, 1.7262e-01],\n",
       "        [1.0000e+00, 1.2101e-16, 1.2101e-16],\n",
       "        [1.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "        [2.3633e-29, 7.2671e-01, 2.7329e-01],\n",
       "        [8.3337e-01, 9.3337e-02, 7.3291e-02],\n",
       "        [4.2071e-41, 8.0533e-01, 1.9467e-01],\n",
       "        [8.8305e-08, 9.2219e-01, 7.7811e-02],\n",
       "        [2.1362e-23, 7.0509e-01, 2.9491e-01],\n",
       "        [4.0553e-18, 9.2196e-01, 7.8036e-02],\n",
       "        [3.6875e-37, 1.7747e-01, 8.2253e-01],\n",
       "        [3.0481e-09, 8.2977e-01, 1.7023e-01],\n",
       "        [1.4265e-41, 3.6756e-01, 6.3244e-01],\n",
       "        [4.3614e-20, 8.4397e-01, 1.5603e-01],\n",
       "        [8.9934e-23, 4.0183e-01, 5.9817e-01],\n",
       "        [1.4013e-45, 3.1531e-01, 6.8469e-01],\n",
       "        [9.3097e-39, 4.6032e-01, 5.3968e-01],\n",
       "        [1.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "        [1.0000e+00, 6.0980e-23, 6.0980e-23],\n",
       "        [6.6385e-32, 8.2261e-01, 1.7739e-01],\n",
       "        [1.0000e+00, 2.0370e-39, 2.0370e-39],\n",
       "        [9.6886e-42, 6.2669e-01, 3.7331e-01],\n",
       "        [1.0000e+00, 1.6848e-29, 1.6848e-29],\n",
       "        [4.1191e-19, 6.8942e-01, 3.1058e-01],\n",
       "        [1.0000e+00, 6.6588e-32, 6.6588e-32],\n",
       "        [5.2185e-35, 8.3176e-01, 1.6824e-01],\n",
       "        [1.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "        [1.0000e+00, 1.4939e-18, 2.3453e-19],\n",
       "        [3.7936e-30, 7.4482e-01, 2.5518e-01],\n",
       "        [4.6481e-42, 7.8521e-01, 2.1479e-01],\n",
       "        [1.9618e-43, 4.4668e-01, 5.5332e-01],\n",
       "        [7.7817e-34, 3.3688e-01, 6.6312e-01],\n",
       "        [4.4043e-42, 2.1247e-01, 7.8753e-01],\n",
       "        [1.0938e-21, 8.2923e-01, 1.7077e-01],\n",
       "        [2.4288e-03, 9.7127e-01, 2.6299e-02],\n",
       "        [1.0922e-20, 6.0053e-01, 3.9947e-01],\n",
       "        [0.0000e+00, 5.1074e-01, 4.8926e-01],\n",
       "        [1.0000e+00, 1.0515e-33, 1.0515e-33],\n",
       "        [7.3389e-25, 9.2271e-01, 7.7290e-02],\n",
       "        [1.4508e-30, 4.6233e-01, 5.3767e-01],\n",
       "        [1.8969e-37, 6.3124e-01, 3.6876e-01],\n",
       "        [2.8919e-21, 7.6642e-01, 2.3358e-01],\n",
       "        [1.0000e+00, 7.8542e-40, 7.8542e-40],\n",
       "        [2.2140e-36, 8.1022e-01, 1.8978e-01],\n",
       "        [1.1081e-29, 7.9403e-01, 2.0597e-01],\n",
       "        [1.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "        [8.5535e-20, 5.2845e-01, 4.7155e-01],\n",
       "        [5.6052e-45, 8.5694e-01, 1.4306e-01],\n",
       "        [0.0000e+00, 3.2146e-01, 6.7854e-01],\n",
       "        [9.7511e-17, 7.5970e-01, 2.4030e-01],\n",
       "        [7.3652e-28, 4.1429e-01, 5.8571e-01],\n",
       "        [1.9777e-21, 9.5182e-01, 4.8177e-02],\n",
       "        [1.5182e-28, 9.6334e-01, 3.6659e-02],\n",
       "        [2.5866e-39, 4.5305e-01, 5.4695e-01],\n",
       "        [5.4651e-44, 2.9928e-01, 7.0072e-01],\n",
       "        [4.5510e-39, 8.6135e-01, 1.3865e-01],\n",
       "        [1.0000e+00, 1.8499e-22, 1.8499e-22],\n",
       "        [1.8672e-36, 9.1604e-01, 8.3964e-02],\n",
       "        [7.0975e-37, 6.7038e-01, 3.2962e-01],\n",
       "        [4.0949e-16, 9.5905e-01, 4.0953e-02],\n",
       "        [3.3321e-26, 9.6445e-01, 3.5551e-02],\n",
       "        [4.0719e-33, 5.4744e-01, 4.5256e-01],\n",
       "        [7.4440e-28, 9.0521e-01, 9.4793e-02],\n",
       "        [1.8258e-41, 5.9737e-01, 4.0263e-01],\n",
       "        [2.0619e-27, 8.7351e-01, 1.2649e-01],\n",
       "        [2.2716e-28, 8.1416e-01, 1.8584e-01],\n",
       "        [1.5530e-24, 8.1543e-01, 1.8457e-01],\n",
       "        [7.2419e-40, 2.1608e-01, 7.8392e-01],\n",
       "        [1.0298e-26, 9.8210e-01, 1.7897e-02],\n",
       "        [6.3557e-04, 7.4128e-01, 2.5808e-01],\n",
       "        [1.0000e+00, 1.0988e-36, 1.0988e-36],\n",
       "        [8.5651e-11, 8.1204e-01, 1.8796e-01],\n",
       "        [3.1927e-27, 7.3008e-01, 2.6992e-01],\n",
       "        [1.8524e-30, 8.9834e-01, 1.0166e-01],\n",
       "        [1.7308e-32, 6.7429e-01, 3.2571e-01],\n",
       "        [1.9947e-23, 7.0132e-01, 2.9868e-01],\n",
       "        [7.5440e-38, 1.5280e-01, 8.4719e-01],\n",
       "        [6.1015e-20, 9.0907e-01, 9.0928e-02],\n",
       "        [1.3974e-25, 8.6861e-01, 1.3139e-01],\n",
       "        [9.3738e-37, 7.2505e-01, 2.7495e-01],\n",
       "        [4.0417e-20, 6.1430e-01, 3.8570e-01]], grad_fn=<SoftmaxBackward0>)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict = model(test)\n",
    "print(len(predict))\n",
    "predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 1, 1, 1, 2, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 0, 0, 1,\n",
       "        0, 1, 1, 1, 1, 2, 1, 2, 1, 2, 2, 2, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1,\n",
       "        1, 2, 2, 2, 1, 1, 1, 1, 0, 1, 2, 1, 1, 0, 1, 1, 0, 1, 1, 2, 1, 2, 1, 1,\n",
       "        2, 2, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 0, 1, 1, 1, 1, 1, 2,\n",
       "        1, 1, 1, 1])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict = torch.max(predict,1)[1]\n",
    "predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pred_PM2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Pred_PM2\n",
       "0          0\n",
       "1          1\n",
       "2          1\n",
       "3          1\n",
       "4          2\n",
       "..       ...\n",
       "95         2\n",
       "96         1\n",
       "97         1\n",
       "98         1\n",
       "99         1\n",
       "\n",
       "[100 rows x 1 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pred = pd.DataFrame(data = {'Pred_PM2' : predict})\n",
    "df_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EG1</th>\n",
       "      <th>EG2</th>\n",
       "      <th>EG3</th>\n",
       "      <th>EG4</th>\n",
       "      <th>EG5</th>\n",
       "      <th>EG6</th>\n",
       "      <th>EG7</th>\n",
       "      <th>EG8</th>\n",
       "      <th>EG9</th>\n",
       "      <th>EG10</th>\n",
       "      <th>...</th>\n",
       "      <th>EG16</th>\n",
       "      <th>EG17</th>\n",
       "      <th>EG18</th>\n",
       "      <th>EG19</th>\n",
       "      <th>EG20</th>\n",
       "      <th>HUM</th>\n",
       "      <th>TMP</th>\n",
       "      <th>WD</th>\n",
       "      <th>WS</th>\n",
       "      <th>Pred_PM2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>583.44</td>\n",
       "      <td>6736.08</td>\n",
       "      <td>5728.32</td>\n",
       "      <td>1272.96</td>\n",
       "      <td>1272.96</td>\n",
       "      <td>583.44</td>\n",
       "      <td>6736.08</td>\n",
       "      <td>5728.32</td>\n",
       "      <td>1272.96</td>\n",
       "      <td>1272.96</td>\n",
       "      <td>...</td>\n",
       "      <td>437.58</td>\n",
       "      <td>5052.06</td>\n",
       "      <td>4296.24</td>\n",
       "      <td>954.72</td>\n",
       "      <td>954.72</td>\n",
       "      <td>68</td>\n",
       "      <td>23.7</td>\n",
       "      <td>0.882948</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>875.16</td>\n",
       "      <td>10104.12</td>\n",
       "      <td>8592.48</td>\n",
       "      <td>1909.44</td>\n",
       "      <td>1909.44</td>\n",
       "      <td>1151.92</td>\n",
       "      <td>13299.44</td>\n",
       "      <td>11309.76</td>\n",
       "      <td>2513.28</td>\n",
       "      <td>2513.28</td>\n",
       "      <td>...</td>\n",
       "      <td>583.44</td>\n",
       "      <td>6736.08</td>\n",
       "      <td>5728.32</td>\n",
       "      <td>1272.96</td>\n",
       "      <td>1272.96</td>\n",
       "      <td>34</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0.190809</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>729.30</td>\n",
       "      <td>8420.10</td>\n",
       "      <td>7160.40</td>\n",
       "      <td>1591.20</td>\n",
       "      <td>1591.20</td>\n",
       "      <td>1092.08</td>\n",
       "      <td>12608.56</td>\n",
       "      <td>10722.24</td>\n",
       "      <td>2382.72</td>\n",
       "      <td>2382.72</td>\n",
       "      <td>...</td>\n",
       "      <td>437.58</td>\n",
       "      <td>5052.06</td>\n",
       "      <td>4296.24</td>\n",
       "      <td>954.72</td>\n",
       "      <td>954.72</td>\n",
       "      <td>58</td>\n",
       "      <td>11.9</td>\n",
       "      <td>0.754710</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>875.16</td>\n",
       "      <td>10104.12</td>\n",
       "      <td>8592.48</td>\n",
       "      <td>1909.44</td>\n",
       "      <td>1909.44</td>\n",
       "      <td>1600.72</td>\n",
       "      <td>18481.04</td>\n",
       "      <td>15716.16</td>\n",
       "      <td>3492.48</td>\n",
       "      <td>3492.48</td>\n",
       "      <td>...</td>\n",
       "      <td>291.72</td>\n",
       "      <td>3368.04</td>\n",
       "      <td>2864.16</td>\n",
       "      <td>636.48</td>\n",
       "      <td>636.48</td>\n",
       "      <td>25</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.275637</td>\n",
       "      <td>1.9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1237.94</td>\n",
       "      <td>14292.58</td>\n",
       "      <td>12154.32</td>\n",
       "      <td>2700.96</td>\n",
       "      <td>2700.96</td>\n",
       "      <td>1806.42</td>\n",
       "      <td>20855.94</td>\n",
       "      <td>17735.76</td>\n",
       "      <td>3941.28</td>\n",
       "      <td>3941.28</td>\n",
       "      <td>...</td>\n",
       "      <td>1301.52</td>\n",
       "      <td>15026.64</td>\n",
       "      <td>12778.56</td>\n",
       "      <td>2839.68</td>\n",
       "      <td>2839.68</td>\n",
       "      <td>66</td>\n",
       "      <td>13.7</td>\n",
       "      <td>-0.173648</td>\n",
       "      <td>0.4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>1237.94</td>\n",
       "      <td>14292.58</td>\n",
       "      <td>12154.32</td>\n",
       "      <td>2700.96</td>\n",
       "      <td>2700.96</td>\n",
       "      <td>1806.42</td>\n",
       "      <td>20855.94</td>\n",
       "      <td>17735.76</td>\n",
       "      <td>3941.28</td>\n",
       "      <td>3941.28</td>\n",
       "      <td>...</td>\n",
       "      <td>1155.66</td>\n",
       "      <td>13342.62</td>\n",
       "      <td>11346.48</td>\n",
       "      <td>2521.44</td>\n",
       "      <td>2521.44</td>\n",
       "      <td>68</td>\n",
       "      <td>13.1</td>\n",
       "      <td>-0.997564</td>\n",
       "      <td>0.3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>875.16</td>\n",
       "      <td>10104.12</td>\n",
       "      <td>8592.48</td>\n",
       "      <td>1909.44</td>\n",
       "      <td>1909.44</td>\n",
       "      <td>583.44</td>\n",
       "      <td>6736.08</td>\n",
       "      <td>5728.32</td>\n",
       "      <td>1272.96</td>\n",
       "      <td>1272.96</td>\n",
       "      <td>...</td>\n",
       "      <td>437.58</td>\n",
       "      <td>5052.06</td>\n",
       "      <td>4296.24</td>\n",
       "      <td>954.72</td>\n",
       "      <td>954.72</td>\n",
       "      <td>58</td>\n",
       "      <td>5.9</td>\n",
       "      <td>0.544639</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>1021.02</td>\n",
       "      <td>11788.14</td>\n",
       "      <td>10024.56</td>\n",
       "      <td>2227.68</td>\n",
       "      <td>2227.68</td>\n",
       "      <td>437.58</td>\n",
       "      <td>5052.06</td>\n",
       "      <td>4296.24</td>\n",
       "      <td>954.72</td>\n",
       "      <td>954.72</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>48</td>\n",
       "      <td>8.4</td>\n",
       "      <td>0.515038</td>\n",
       "      <td>1.3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>583.44</td>\n",
       "      <td>6736.08</td>\n",
       "      <td>5728.32</td>\n",
       "      <td>1272.96</td>\n",
       "      <td>1272.96</td>\n",
       "      <td>729.30</td>\n",
       "      <td>8420.10</td>\n",
       "      <td>7160.40</td>\n",
       "      <td>1591.20</td>\n",
       "      <td>1591.20</td>\n",
       "      <td>...</td>\n",
       "      <td>654.50</td>\n",
       "      <td>7556.50</td>\n",
       "      <td>6426.00</td>\n",
       "      <td>1428.00</td>\n",
       "      <td>1428.00</td>\n",
       "      <td>51</td>\n",
       "      <td>2.8</td>\n",
       "      <td>0.374607</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>1522.18</td>\n",
       "      <td>17574.26</td>\n",
       "      <td>14945.04</td>\n",
       "      <td>3321.12</td>\n",
       "      <td>3321.12</td>\n",
       "      <td>1013.54</td>\n",
       "      <td>11701.78</td>\n",
       "      <td>9951.12</td>\n",
       "      <td>2211.36</td>\n",
       "      <td>2211.36</td>\n",
       "      <td>...</td>\n",
       "      <td>437.58</td>\n",
       "      <td>5052.06</td>\n",
       "      <td>4296.24</td>\n",
       "      <td>954.72</td>\n",
       "      <td>954.72</td>\n",
       "      <td>30</td>\n",
       "      <td>12.1</td>\n",
       "      <td>0.945519</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        EG1       EG2       EG3      EG4      EG5      EG6       EG7  \\\n",
       "0    583.44   6736.08   5728.32  1272.96  1272.96   583.44   6736.08   \n",
       "1    875.16  10104.12   8592.48  1909.44  1909.44  1151.92  13299.44   \n",
       "2    729.30   8420.10   7160.40  1591.20  1591.20  1092.08  12608.56   \n",
       "3    875.16  10104.12   8592.48  1909.44  1909.44  1600.72  18481.04   \n",
       "4   1237.94  14292.58  12154.32  2700.96  2700.96  1806.42  20855.94   \n",
       "..      ...       ...       ...      ...      ...      ...       ...   \n",
       "95  1237.94  14292.58  12154.32  2700.96  2700.96  1806.42  20855.94   \n",
       "96   875.16  10104.12   8592.48  1909.44  1909.44   583.44   6736.08   \n",
       "97  1021.02  11788.14  10024.56  2227.68  2227.68   437.58   5052.06   \n",
       "98   583.44   6736.08   5728.32  1272.96  1272.96   729.30   8420.10   \n",
       "99  1522.18  17574.26  14945.04  3321.12  3321.12  1013.54  11701.78   \n",
       "\n",
       "         EG8      EG9     EG10  ...     EG16      EG17      EG18     EG19  \\\n",
       "0    5728.32  1272.96  1272.96  ...   437.58   5052.06   4296.24   954.72   \n",
       "1   11309.76  2513.28  2513.28  ...   583.44   6736.08   5728.32  1272.96   \n",
       "2   10722.24  2382.72  2382.72  ...   437.58   5052.06   4296.24   954.72   \n",
       "3   15716.16  3492.48  3492.48  ...   291.72   3368.04   2864.16   636.48   \n",
       "4   17735.76  3941.28  3941.28  ...  1301.52  15026.64  12778.56  2839.68   \n",
       "..       ...      ...      ...  ...      ...       ...       ...      ...   \n",
       "95  17735.76  3941.28  3941.28  ...  1155.66  13342.62  11346.48  2521.44   \n",
       "96   5728.32  1272.96  1272.96  ...   437.58   5052.06   4296.24   954.72   \n",
       "97   4296.24   954.72   954.72  ...     0.00      0.00      0.00     0.00   \n",
       "98   7160.40  1591.20  1591.20  ...   654.50   7556.50   6426.00  1428.00   \n",
       "99   9951.12  2211.36  2211.36  ...   437.58   5052.06   4296.24   954.72   \n",
       "\n",
       "       EG20  HUM   TMP        WD   WS  Pred_PM2  \n",
       "0    954.72   68  23.7  0.882948  0.7         0  \n",
       "1   1272.96   34   3.5  0.190809  3.5         1  \n",
       "2    954.72   58  11.9  0.754710  0.6         1  \n",
       "3    636.48   25   7.0  0.275637  1.9         1  \n",
       "4   2839.68   66  13.7 -0.173648  0.4         2  \n",
       "..      ...  ...   ...       ...  ...       ...  \n",
       "95  2521.44   68  13.1 -0.997564  0.3         2  \n",
       "96   954.72   58   5.9  0.544639  2.0         1  \n",
       "97     0.00   48   8.4  0.515038  1.3         1  \n",
       "98  1428.00   51   2.8  0.374607  0.6         1  \n",
       "99   954.72   30  12.1  0.945519  0.9         1  \n",
       "\n",
       "[100 rows x 25 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mergy_by_col = pd.concat([df_test, df_pred], axis=1)\n",
    "mergy_by_col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install openpyxl\n",
    "mergy_by_col.to_excel(excel_writer='10th_homework.xlsx')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('kotorch')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e394b0e5950b2ed9ac02d3d0f43da50df004fa03f183c9ffe2862d4a06a95d21"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
