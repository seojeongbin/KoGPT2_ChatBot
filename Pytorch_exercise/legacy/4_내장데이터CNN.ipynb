{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Qs13mWf5o83"
      },
      "source": [
        "## pytorch를 통한 CNN 구현\n",
        "- task : 이미지 다중분류 (레이블 5개)\n",
        "- 참고 (model.train(), model.eval(), torch.no_grad()란?) : https://tigris-data-science.tistory.com/entry/PyTorch-modeltrain-vs-modeleval-vs-torchnograd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "PMX4g85Dwzz4"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision\n",
        "from tqdm import tqdm\n",
        "import torchsummary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KXQZPYEKxPjV",
        "outputId": "855a3afe-ae8e-4514-e7f2-4aede78b7c8b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/download.tensorflow.org/example_images/flower_photos.tgz\n",
            "228818944/228813984 [==============================] - 1s 0us/step\n",
            "228827136/228813984 [==============================] - 1s 0us/step\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "import pathlib\n",
        "dataset_url = \"https://storage.googleapis.com/download.tensorflow.org/example_images/flower_photos.tgz\"\n",
        "data_dir = tf.keras.utils.get_file(origin=dataset_url, \n",
        "                                   fname='flower_photos', \n",
        "                                   untar=True,\n",
        "                                   )\n",
        "data_dir = pathlib.Path(data_dir)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RfBzJF_y5k0g"
      },
      "source": [
        "### DataLoader\n",
        "- validation set 경우 shuffle False\n",
        "- test set과 마찬가지로 torch.no_grad()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "baEQg6NIxjiG",
        "outputId": "2d030759-39f7-4ab1-eab2-5242c40c1e27"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "3670\n"
          ]
        }
      ],
      "source": [
        "from torchvision.datasets import ImageFolder\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "from torchvision.transforms import transforms as T\n",
        "t = T.Compose([T.Resize((224,224)),T.ToTensor(),T.Normalize((0.5,0.5,0.5), (0.25,0.25,0.25))])\n",
        "dataset = ImageFolder(root = data_dir,transform = t)\n",
        "print(dataset.__len__()) # Dasiy, dandelion(민들레), roses, sunflowers, tulibs이란 라벨을 가진 총 3670장의 이미지"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "9gapwAGT5Nmr"
      },
      "outputs": [],
      "source": [
        "train_size = int(dataset.__len__() * 0.8)\n",
        "valid_size = dataset.__len__() - train_size\n",
        "\n",
        "training_data, valid_data = random_split(dataset, [train_size, valid_size])\n",
        "\n",
        "train_loader = DataLoader(training_data, batch_size=32, shuffle=True)\n",
        "valid_loader = DataLoader(valid_data, batch_size=32, shuffle=False) # valid는 섞지않는다!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tfms5y_059G6"
      },
      "source": [
        "### 모델 정의\n",
        "- 고려사항\n",
        "    - 모델의 정도: 깊게 쌓을 것인가(Layer를 늘릴지), 혹은 넓게 쌓을 것인가(Filter를 늘릴지), kernal_size를 어떻게 조절할 것인지?\n",
        "    - Dropout: Overfitting을 어떻게 방지할 것인가?\n",
        "    - Batch Normalization: 배치 단위로 정규화를 넣어줄 것인지\n",
        "    - Activation function: 다른걸 써볼 수 있을지"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "-d_wbG5a50QG"
      },
      "outputs": [],
      "source": [
        "class myCNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(myCNN, self).__init__()\n",
        "        self.layer1 = nn.Sequential(\n",
        "            # Sequential : 하나의 층당 다음과정을 순서대로 수행 (conv => 활성화함수 => pooling)\n",
        "            # RGB 3채널의 이미지를 입력으로 받아서, 이미지 하나당 32개의 필터뱅크 적용 (커널사이즈 3짜리)\n",
        "            nn.Conv2d(in_channels = 3, out_channels = 32, kernel_size = 3, stride = 1, padding = 1),\n",
        "            nn.ReLU(inplace = True),\n",
        "            nn.MaxPool2d(2, 2)\n",
        "        )\n",
        "        self.layer2 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, stride=1, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(2,2)\n",
        "        )\n",
        "        self.fc1 = nn.Linear(64 * 56 * 56, 128)\n",
        "        self.fc2 = nn.Linear(128, 5) # 분류해야 할 이미지가 5종류\n",
        "    \n",
        "    def forward(self, x):\n",
        "        # forward : 연산순서 정의\n",
        "        x = self.layer1(x)\n",
        "        x = self.layer2(x)\n",
        "        x = x.view(-1, 64*56*56)\n",
        "        x = F.relu(self.fc1(x)) # 여긴 F.relu인것을 주목 nn.ReLU가 아니라\n",
        "        return self.fc2(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oGlBPpCP6xqG"
      },
      "source": [
        "### 손실함수, 옵티마이저 설정\n",
        "- Loss: 어떤 loss를 사용할 것인가?\n",
        "- Optim: SGD 외에 RMSprop, Adam 등으로 바꾸면 학습에 어떤 영향을 미치는가?\n",
        "- Learning rate: 어느정도의 속도로 학습할 것인가?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VyVjqY626tYx",
        "outputId": "7925d25a-899f-4327-bac9-f9a07d8abd87"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1         [-1, 32, 224, 224]             896\n",
            "              ReLU-2         [-1, 32, 224, 224]               0\n",
            "         MaxPool2d-3         [-1, 32, 112, 112]               0\n",
            "            Conv2d-4         [-1, 64, 112, 112]          18,496\n",
            "              ReLU-5         [-1, 64, 112, 112]               0\n",
            "         MaxPool2d-6           [-1, 64, 56, 56]               0\n",
            "            Linear-7                  [-1, 128]      25,690,240\n",
            "            Linear-8                    [-1, 5]             645\n",
            "================================================================\n",
            "Total params: 25,710,277\n",
            "Trainable params: 25,710,277\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.57\n",
            "Forward/backward pass size (MB): 41.34\n",
            "Params size (MB): 98.08\n",
            "Estimated Total Size (MB): 140.00\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "gpu = torch.device(\"cuda\")\n",
        "model = myCNN().to('cpu')\n",
        "loss_fn = torch.nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
        "\n",
        "import torchsummary\n",
        "torchsummary.summary(model, (3, 224, 224)) # 224*224 RGB 이미지"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IE4Yt-Q_7Npj"
      },
      "source": [
        "### 학습 돌리기"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "writ5U__7B2Z",
        "outputId": "7460c93e-2ede-4a7e-f017-30847a160c43"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 92/92 [00:19<00:00,  4.73it/s]\n",
            "100%|██████████| 23/23 [00:03<00:00,  6.48it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch:1/5.. Train Loss: 1.266.. Val Loss: 1.146.. Train Acc:0.488.. Val Acc:0.548..\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 92/92 [00:18<00:00,  4.96it/s]\n",
            "100%|██████████| 23/23 [00:03<00:00,  5.94it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch:2/5.. Train Loss: 0.978.. Val Loss: 1.032.. Train Acc:0.612.. Val Acc:0.564..\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 92/92 [00:18<00:00,  4.96it/s]\n",
            "100%|██████████| 23/23 [00:03<00:00,  6.54it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch:3/5.. Train Loss: 0.809.. Val Loss: 1.147.. Train Acc:0.693.. Val Acc:0.553..\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 92/92 [00:18<00:00,  4.96it/s]\n",
            "100%|██████████| 23/23 [00:03<00:00,  6.49it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch:4/5.. Train Loss: 0.663.. Val Loss: 0.983.. Train Acc:0.767.. Val Acc:0.636..\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 92/92 [00:19<00:00,  4.81it/s]\n",
            "100%|██████████| 23/23 [00:03<00:00,  6.42it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch:5/5.. Train Loss: 0.534.. Val Loss: 1.023.. Train Acc:0.826.. Val Acc:0.606..\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "epochs = 5\n",
        "torch.cuda.empty_cache()\n",
        "train_losses = []\n",
        "val_losses = []\n",
        "train_acc = []\n",
        "val_acc = []\n",
        "\n",
        "for epoch_num in range(epochs):\n",
        "    \n",
        "    # 1. train\n",
        "    model.train() # ★ layer들을 Training mode로 바꿔준다\n",
        "    running_loss = 0\n",
        "    running_accuracy = 0\n",
        "    \n",
        "    for _, data in enumerate(tqdm(train_loader)):\n",
        "        # 준비물\n",
        "        inputs, labels = data # 이미지, 라벨\n",
        "        inputs = inputs.to(gpu).float()\n",
        "        labels = inputs.to(gpu).long()\n",
        "        optimizer.zero_grad() # ★주의\n",
        "        \n",
        "        # 순전파\n",
        "        outputs = model(inputs) # 이미지 모델에 넣기 => 값 : 다중확률\n",
        "        print(f'outputs : {outputs}')\n",
        "        _, preds = torch.max(outputs, 1) # 가장놓은걸 pred로 취급\n",
        "        loss = loss_fn(outputs, labels)\n",
        "        \n",
        "        # 역전파\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item()\n",
        "        running_accuracy += torch.sum(preds == labels.data).detach().cpu().numpy()/inputs.size()\n",
        "    \n",
        "    # 2. validation\n",
        "    model.eval() # ★ layer들을 eval mode로 바꿔준다\n",
        "    val_loss = 0\n",
        "    val_accuracy = 0\n",
        "    with torch.no_grad(): # ★ 역전파를 안하기때문에 gradient 를 사용하지않는다\n",
        "        for _, data in enumerate(tqdm(valid_loader)):\n",
        "            # 준비물                \n",
        "            inputs, labels = data\n",
        "            inputs = inputs.to(gpu).float()\n",
        "            labels = labels.to(gpu).long()\n",
        "\n",
        "            # 순전파\n",
        "            outputs = model(inputs)\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "\n",
        "            # 역전파과정은 없음. 지표만 더해주기.\n",
        "            loss = loss_fn(outputs, labels)\n",
        "            val_loss += loss.item()\n",
        "            val_accuracy += torch.sum(preds == labels.data).detach().cpu().numpy()/inputs.size(0)\n",
        "            \n",
        "    # 3. 각 배치별 평균성능 계산하기\n",
        "    train_losses.append(running_loss / len(train_loader))\n",
        "    val_losses.append(val_loss / len(valid_loader))\n",
        "    train_acc.append(running_accuracy / len(train_loader))\n",
        "    val_acc.append(val_accuracy / len(valid_loader))\n",
        "    \n",
        "    print(\"Epoch:{}/{}..\".format(epoch_num + 1, epochs),\n",
        "            \"Train Loss: {:.3f}..\".format(running_loss / len(train_loader)),\n",
        "            \"Val Loss: {:.3f}..\".format(val_loss / len(valid_loader)),\n",
        "            \"Train Acc:{:.3f}..\".format(running_accuracy / len(train_loader)),\n",
        "            \"Val Acc:{:.3f}..\".format(val_accuracy / len(valid_loader)))\n",
        "\n",
        "history = {'train_loss': train_losses, 'val_loss': val_losses,\n",
        "            'train_acc': train_acc, 'val_acc': val_acc}    "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uPvthYGU803u"
      },
      "source": [
        "### 모델 평가"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k_q-06fl82p0",
        "outputId": "883898be-8be0-499c-c6b7-af260dbd3e46"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 23/23 [00:03<00:00,  6.47it/s]\n"
          ]
        }
      ],
      "source": [
        "model.eval() # ★ eval 모드\n",
        "y_pred = []\n",
        "y_true = []\n",
        "\n",
        "with torch.no_grad() : # ★ gradient 사용하지 않는다\n",
        "    for _, data in enumerate(tqdm(valid_loader)):\n",
        "        inputs, labels = data                    \n",
        "        inputs = inputs.to(gpu).float()            \n",
        "        outputs = model(inputs)\n",
        "        _, preds = torch.max(outputs, 1)                        \n",
        "        y_pred += list(preds.detach().cpu().numpy())\n",
        "        y_true += list(labels.detach().numpy())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DvQNkBeS84st",
        "outputId": "904b5e3e-8d85-4842-b26b-b4a67c438f87"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            " Classification report \n",
            "\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "       daisy       0.68      0.42      0.52       118\n",
            "   dandelion       0.52      0.86      0.65       177\n",
            "       roses       0.53      0.55      0.54       141\n",
            "  sunflowers       0.80      0.65      0.72       143\n",
            "      tulibs       0.68      0.46      0.55       155\n",
            "\n",
            "    accuracy                           0.61       734\n",
            "   macro avg       0.64      0.59      0.60       734\n",
            "weighted avg       0.64      0.61      0.60       734\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# 레이블별 confusion matrix를 통한 예측 리포트\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "class_names = ['daisy','dandelion','roses','sunflowers','tulibs']\n",
        "print('\\n Classification report \\n\\n',\n",
        "  classification_report(\n",
        "      y_true,\n",
        "      y_pred,\n",
        "       target_names=class_names\n",
        "      )\n",
        "  )"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.8.13 ('kotorch')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.13"
    },
    "vscode": {
      "interpreter": {
        "hash": "e394b0e5950b2ed9ac02d3d0f43da50df004fa03f183c9ffe2862d4a06a95d21"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
